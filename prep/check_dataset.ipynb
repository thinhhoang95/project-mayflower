{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /Volumes/CrucialX/project-mayflower\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ROOT = os.getenv('PROJECT_ROOT')\n",
    "print(f'PROJECT_ROOT: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remove all sequences with only two waypoints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 .pt files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8k/_h2zg_z51q9fpsbmsh42bd3h0000gn/T/ipykernel_7421/433117710.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load(pt_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File: train.03.ds.pt\n",
      "Found 5364 rows with less than 3 non-nan values\n",
      "Invalid row indices: [     9      9     92 ... 153390 153412 153412]\n",
      "Total rows after removal: 150778\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.03.ds.pt\n",
      "\n",
      "File: train.04.ds.pt\n",
      "Found 6292 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    23     23     37 ... 164917 164966 164966]\n",
      "Total rows after removal: 161837\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.04.ds.pt\n",
      "\n",
      "File: train.05.ds.pt\n",
      "Found 7252 rows with less than 3 non-nan values\n",
      "Invalid row indices: [     3      3     40 ... 181981 181983 181983]\n",
      "Total rows after removal: 178382\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.05.ds.pt\n",
      "\n",
      "File: train.06.ds.pt\n",
      "Found 7332 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    36     36    115 ... 177417 177425 177425]\n",
      "Total rows after removal: 173794\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.06.ds.pt\n",
      "\n",
      "File: train.07.ds.pt\n",
      "Found 7908 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    91     91    181 ... 188834 188894 188894]\n",
      "Total rows after removal: 184951\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.07.ds.pt\n",
      "\n",
      "File: train.08.ds.pt\n",
      "Found 7550 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    73     73    138 ... 187482 187489 187489]\n",
      "Total rows after removal: 183739\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.08.ds.pt\n",
      "\n",
      "File: train.09.ds.pt\n",
      "Found 9250 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    10     10     38 ... 195408 195412 195412]\n",
      "Total rows after removal: 190788\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.09.ds.pt\n",
      "\n",
      "File: train.10.ds.pt\n",
      "Found 8638 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    67     67     84 ... 200639 200641 200641]\n",
      "Total rows after removal: 196416\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.10.ds.pt\n",
      "\n",
      "File: val.ds.pt\n",
      "Found 1496 rows with less than 3 non-nan values\n",
      "Invalid row indices: [   15    15    33 ... 34375 34387 34387]\n",
      "Total rows after removal: 33679\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/val.ds.pt\n",
      "\n",
      "File: test.ds.pt\n",
      "Found 1520 rows with less than 3 non-nan values\n",
      "Invalid row indices: [   30    30   165 ... 34297 34365 34365]\n",
      "Total rows after removal: 33667\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/test.ds.pt\n",
      "\n",
      "File: train.01.ds.pt\n",
      "Found 3696 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    16     16     43 ... 119310 119332 119332]\n",
      "Total rows after removal: 117513\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.01.ds.pt\n",
      "\n",
      "File: train.02.ds.pt\n",
      "Found 5340 rows with less than 3 non-nan values\n",
      "Invalid row indices: [    43     43     59 ... 140729 140748 140748]\n",
      "Total rows after removal: 138131\n",
      "Saved cleaned dataset to /Volumes/CrucialX/project-mayflower/data/train.02.ds.pt\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Get all .pt files from the data/csv directory\n",
    "data_dir = Path(PROJECT_ROOT) / 'data'\n",
    "pt_files = glob.glob(str(data_dir / '*.ds.pt'))\n",
    "total_rows = 0\n",
    "\n",
    "print(f\"Found {len(pt_files)} .pt files\")\n",
    "\n",
    "for pt_file in pt_files:\n",
    "    # Load the dataset\n",
    "    data = torch.load(pt_file)\n",
    "    \n",
    "    # Count non-nan values per row\n",
    "    non_nan_counts = np.count_nonzero(~np.isnan(data), axis=1)\n",
    "    \n",
    "    # Check which rows have less than 3 non-nan values\n",
    "    invalid_rows = np.where(non_nan_counts < 3)[0]\n",
    "    \n",
    "    if len(invalid_rows) > 0:\n",
    "        print(f\"\\nFile: {Path(pt_file).name}\")\n",
    "        print(f\"Found {len(invalid_rows)} rows with less than 3 non-nan values\")\n",
    "        print(f\"Invalid row indices: {invalid_rows}\")\n",
    "        # Remove the invalid rows\n",
    "        data = np.delete(data, invalid_rows, axis=0)\n",
    "        total_rows += len(data)\n",
    "        print(f\"Total rows after removal: {len(data)}\")\n",
    "        # Save the cleaned dataset\n",
    "        torch.save(data, pt_file)\n",
    "        print(f\"Saved cleaned dataset to {pt_file}\")\n",
    "    else:\n",
    "        print(f\"\\nFile: {Path(pt_file).name}\")\n",
    "        print(\"All rows have at least 3 non-nan values\")\n",
    "        print(f\"Total rows: {len(data)}\")\n",
    "        total_rows += len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1743675\n"
     ]
    }
   ],
   "source": [
    "print(f'Total rows: {total_rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mayflower",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
